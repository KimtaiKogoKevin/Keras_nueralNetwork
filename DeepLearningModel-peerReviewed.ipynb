{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A formal definition of the networks structure , including the number of inputs , number of hidden layers  and number of nodes in the hidden layers as well as the number of node in the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8 # number of inputs\n",
    "num_of_hidden_layers = 1  \n",
    "m =[10] # number of nodes in the single hidden layer\n",
    "num_nodes_output = 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the numpy library we initialize the weights and the biases to random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_1': {'node_1': {'weights': array([0.89, 0.64, 0.23, 0.94, 0.93, 0.83, 0.46, 0.57]), 'bias': array([0.81])}, 'node_2': {'weights': array([0.06, 0.83, 0.46, 0.96, 0.35, 0.01, 0.57, 0.38]), 'bias': array([0.42])}, 'node_3': {'weights': array([0.14, 0.96, 0.7 , 0.69, 0.52, 0.53, 0.02, 0.7 ]), 'bias': array([0.52])}, 'node_4': {'weights': array([0.61, 0.05, 0.02, 0.15, 0.38, 0.12, 0.39, 0.56]), 'bias': array([0.55])}, 'node_5': {'weights': array([0.25, 0.89, 0.93, 0.48, 0.36, 0.11, 0.27, 0.07]), 'bias': array([0.89])}, 'node_6': {'weights': array([0.2 , 0.64, 0.13, 0.63, 0.53, 0.79, 0.23, 0.15]), 'bias': array([0.33])}, 'node_7': {'weights': array([0.3 , 0.32, 0.75, 0.6 , 0.07, 0.24, 0.36, 0.68]), 'bias': array([0.27])}, 'node_8': {'weights': array([0.68, 0.97, 0.39, 0.11, 0.89, 0.89, 0.49, 0.32]), 'bias': array([0.07])}, 'node_9': {'weights': array([0.03, 0.71, 0.7 , 0.71, 0.3 , 0.83, 0.79, 0.77]), 'bias': array([0.97])}, 'node_10': {'weights': array([0.57, 0.76, 0.76, 0.38, 0.82, 0.24, 0.79, 0.83]), 'bias': array([0.97])}}, 'output': {'node_1': {'weights': array([0.02, 0.23, 0.8 , 0.01, 0.56, 0.26, 0.07, 0.6 , 0.37, 0.29]), 'bias': array([0.17])}}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # import the Numpy library\n",
    "\n",
    "num_nodes_previous = n # number of nodes in the previous layer\n",
    "\n",
    "network = {} # initialize network an an empty dictionary\n",
    "\n",
    "# loop through each layer and randomly initialize the weights and biases associated with each node\n",
    "# notice how we are adding 1 to the number of hidden layers in order to include the output layer\n",
    "for layer in range(num_of_hidden_layers + 1): \n",
    "    \n",
    "    # determine name of layer\n",
    "    if layer == num_of_hidden_layers:\n",
    "        layer_name = 'output'\n",
    "        num_nodes = num_nodes_output \n",
    "    else:\n",
    "        layer_name = 'layer_{}'.format(layer + 1)\n",
    "        num_nodes = m[layer]\n",
    "    \n",
    "    # initialize weights and biases associated with each node in the current layer\n",
    "    network[layer_name] = {}\n",
    "    for node in range(num_nodes):\n",
    "        node_name = 'node_{}'.format(node+1)\n",
    "        network[layer_name][node_name] = {\n",
    "            'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals=2),\n",
    "            'bias': np.around(np.random.uniform(size=1), decimals=2),\n",
    "        }\n",
    "    \n",
    "    num_nodes_previous = num_nodes\n",
    "    \n",
    "print(network) # print network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
