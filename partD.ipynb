{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "# importing data\n",
    "df = pd.read_csv('concrete_data.csv')\n",
    "  \n",
    "# head of the data\n",
    "#print(df.head())\n",
    "\n",
    "#prepare the X independent   variables \n",
    "\n",
    "X1 = df['Cement']\n",
    "X2=df['Blast Furnace Slag']\n",
    "X3 =df['Fly Ash']\n",
    "X4=df['Water']\n",
    "X5=df['Superplasticizer']\n",
    "X6=df['Coarse Aggregate']\n",
    "X7=df['Fine Aggregate']\n",
    "X8=df['Age']\n",
    "X = pd.concat([X1,X2,X3,X4,X5,X6,X7,X8], axis=1)\n",
    "#X.head(20)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the Y  dependent variables \n",
    "Y1 = df['Strength']\n",
    "Y = pd.concat([Y1], axis=1)\n",
    "#Y.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 11ms/step\n",
      "Epoch 1 , Mean Squared Error: 1.3845157718625125\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "Epoch 2 , Mean Squared Error: 1.479022963642243\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "Epoch 3 , Mean Squared Error: 1.6041911705604934\n",
      "10/10 [==============================] - 0s 16ms/step\n",
      "Epoch 4 , Mean Squared Error: 1.7405592301561839\n",
      "10/10 [==============================] - 0s 14ms/step\n",
      "Epoch 5 , Mean Squared Error: 1.8556193138761667\n",
      "10/10 [==============================] - 1s 23ms/step\n",
      "Epoch 6 , Mean Squared Error: 1.9362340589994156\n",
      "10/10 [==============================] - 1s 29ms/step\n",
      "Epoch 7 , Mean Squared Error: 1.9827063452459386\n",
      "10/10 [==============================] - 1s 29ms/step\n",
      "Epoch 8 , Mean Squared Error: 2.0083732287806755\n",
      "10/10 [==============================] - 0s 27ms/step\n",
      "Epoch 9 , Mean Squared Error: 2.0228161684332284\n",
      "10/10 [==============================] - 0s 14ms/step\n",
      "Epoch 10 , Mean Squared Error: 2.0314804354468023\n",
      "10/10 [==============================] - 1s 29ms/step\n",
      "Epoch 11 , Mean Squared Error: 2.0386742458692795\n",
      "10/10 [==============================] - 1s 23ms/step\n",
      "Epoch 12 , Mean Squared Error: 2.042415219804754\n",
      "10/10 [==============================] - 0s 28ms/step\n",
      "Epoch 13 , Mean Squared Error: 2.044245743911478\n",
      "10/10 [==============================] - 1s 35ms/step\n",
      "Epoch 14 , Mean Squared Error: 2.0452110582468976\n",
      "10/10 [==============================] - 0s 24ms/step\n",
      "Epoch 15 , Mean Squared Error: 2.0457711850613136\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "Epoch 16 , Mean Squared Error: 2.046154059508655\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "Epoch 17 , Mean Squared Error: 2.0464228636748083\n",
      "10/10 [==============================] - 0s 14ms/step\n",
      "Epoch 18 , Mean Squared Error: 2.046637449336244\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "Epoch 19 , Mean Squared Error: 2.0467938254757487\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "Epoch 20 , Mean Squared Error: 2.046911498658507\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "Epoch 21 , Mean Squared Error: 2.047012401220674\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "Epoch 22 , Mean Squared Error: 2.0470912438489304\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "Epoch 23 , Mean Squared Error: 2.0471561103961995\n",
      "10/10 [==============================] - 1s 9ms/step\n",
      "Epoch 24 , Mean Squared Error: 2.0472097984733653\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "Epoch 25 , Mean Squared Error: 2.0472544338597096\n",
      "10/10 [==============================] - 0s 28ms/step\n",
      "Epoch 26 , Mean Squared Error: 2.047292465238229\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "Epoch 27 , Mean Squared Error: 2.0473254733450474\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "Epoch 28 , Mean Squared Error: 2.0473550035174646\n",
      "10/10 [==============================] - 0s 16ms/step\n",
      "Epoch 29 , Mean Squared Error: 2.0473797660941573\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "Epoch 30 , Mean Squared Error: 2.047403046713229\n",
      "10/10 [==============================] - 0s 13ms/step\n",
      "Epoch 31 , Mean Squared Error: 2.04742110512687\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "Epoch 32 , Mean Squared Error: 2.0474387038284374\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "Epoch 33 , Mean Squared Error: 2.0474543831649648\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "Epoch 34 , Mean Squared Error: 2.0474687459565026\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "Epoch 35 , Mean Squared Error: 2.047481063951216\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "Epoch 36 , Mean Squared Error: 2.0474920415591695\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "Epoch 37 , Mean Squared Error: 2.047503678266044\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "Epoch 38 , Mean Squared Error: 2.0475130089683335\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "Epoch 39 , Mean Squared Error: 2.0475208907878395\n",
      "10/10 [==============================] - 0s 16ms/step\n",
      "Epoch 40 , Mean Squared Error: 2.047529281203168\n",
      "10/10 [==============================] - 0s 13ms/step\n",
      "Epoch 41 , Mean Squared Error: 2.047536078890373\n",
      "10/10 [==============================] - 0s 13ms/step\n",
      "Epoch 42 , Mean Squared Error: 2.0475432452559064\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "Epoch 43 , Mean Squared Error: 2.047549348681367\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "Epoch 44 , Mean Squared Error: 2.0475548745678602\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "Epoch 45 , Mean Squared Error: 2.0475602779127384\n",
      "10/10 [==============================] - 0s 13ms/step\n",
      "Epoch 46 , Mean Squared Error: 2.047565078577288\n",
      "10/10 [==============================] - 0s 12ms/step\n",
      "Epoch 47 , Mean Squared Error: 2.047569614901396\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "Epoch 48 , Mean Squared Error: 2.047573824083913\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "Epoch 49 , Mean Squared Error: 2.047577499679778\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "Epoch 50 , Mean Squared Error: 2.047581310270907\n",
      "[1.3845157718625125, 1.479022963642243, 1.6041911705604934, 1.7405592301561839, 1.8556193138761667, 1.9362340589994156, 1.9827063452459386, 2.0083732287806755, 2.0228161684332284, 2.0314804354468023, 2.0386742458692795, 2.042415219804754, 2.044245743911478, 2.0452110582468976, 2.0457711850613136, 2.046154059508655, 2.0464228636748083, 2.046637449336244, 2.0467938254757487, 2.046911498658507, 2.047012401220674, 2.0470912438489304, 2.0471561103961995, 2.0472097984733653, 2.0472544338597096, 2.047292465238229, 2.0473254733450474, 2.0473550035174646, 2.0473797660941573, 2.047403046713229, 2.04742110512687, 2.0474387038284374, 2.0474543831649648, 2.0474687459565026, 2.047481063951216, 2.0474920415591695, 2.047503678266044, 2.0475130089683335, 2.0475208907878395, 2.047529281203168, 2.047536078890373, 2.0475432452559064, 2.047549348681367, 2.0475548745678602, 2.0475602779127384, 2.047565078577288, 2.047569614901396, 2.047573824083913, 2.047577499679778, 2.047581310270907]\n",
      "Mean:  1.998353392697848\n",
      "Standard Deviation:  0.14061304684642192\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Split the data\n",
    "x_train, x_test,y_train,y_test = train_test_split(X,Y,test_size =0.3)\n",
    "# print the data\n",
    "# x_train\n",
    "# Manually normalize the data for the indepnedent x variables by subtracting the mean and dividing by the standard deviation\n",
    "x_train_normalized = (x_train - np.mean(x_train, axis=0)) / np.std(x_train, axis=0)\n",
    "x_test_normalized = (x_test - np.mean(x_train, axis=0)) / np.std(x_train, axis=0)\n",
    "\n",
    "# Manually normalize the data for the dependent y variables by subtracting the mean and dividing by the standard deviation\n",
    "y_train_normalized = (y_train - np.mean(y_train, axis=0)) / np.std(y_train, axis=0)\n",
    "y_test_normalized = (y_test - np.mean(y_train, axis=0)) / np.std(y_train, axis=0)\n",
    "\n",
    "# Create a neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x_train_normalized.shape[1], activation='relu',use_bias=True))  # Hidden layer one  with 10 nodes and ReLU activation\n",
    "model.add(Dense(10, input_dim=x_train_normalized.shape[1], activation='relu',use_bias=True))  # Hidden layer two  with 10 nodes and ReLU activation\n",
    "model.add(Dense(10, input_dim=x_train_normalized.shape[1], activation='relu',use_bias=True))  # Hidden layer three  with 10 nodes and ReLU activation\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid',use_bias=True))  # Output layer with 1 node and sigmoid activation\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with 50 epochs\n",
    "epochs = 50\n",
    "mse_list=[]\n",
    "y_pred_list=[]\n",
    "for epoch in range(epochs):\n",
    "    model.fit(x_train_normalized,y_train,epochs=1,verbose=0)\n",
    "    y_pred = model.predict(x_test_normalized)\n",
    "    y_pred_list.append(y_pred)\n",
    "    # print(\"y_pred : \",y_pred)\n",
    "    #evaluate model on the normalized test data\n",
    "    mse = mean_squared_error(y_test_normalized,y_pred)\n",
    "    mse_list.append(mse)\n",
    "    print(f\"Epoch {epoch +1} , Mean Squared Error: {mse}\")\n",
    "#   List of Mean Squared errors for 50 epochs\n",
    "print(mse_list) \n",
    "\n",
    "# Calculate the mean\n",
    "mean_mse = np.mean(mse_list)\n",
    "\n",
    "# Calculate the standard deviation\n",
    "std_dev_mse = np.std(mse_list)\n",
    "\n",
    "# Print the results\n",
    "print(\"Mean: \", mean_mse)\n",
    "print(\"Standard Deviation: \", std_dev_mse)\n",
    "# print(\"y_prediction list: \" ,y_pred_list)\n",
    "\n",
    "\n",
    "#observation , decreased mean squared error after normalization\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean squared errors slightly increases , this can be attributed to having too many nuerons in the nueral network making the trainig time for the model very large . From some research i determined that there a certain rules to follow for the number of hidden layers to have in a nueral network which are \n",
    "1.The number of hidden neurons should be between the size of the input layer and the size of the output layer.\n",
    "2.The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer.\n",
    "3.The number of hidden neurons should be less than twice the size of the input layer.\n",
    "In this case the number of hidden layers breaches all the above constraints and hence the slight increase in the mean squared error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
